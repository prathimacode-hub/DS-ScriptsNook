
nlp image

# Project Title

# :dart: **Text Preprocessing in Natural language processing**

Text preprocessing is traditionally an important step for natural language processing (NLP) tasks. It transforms text into a more digestible form so that machine learning algorithms can perform better.

Text preprocessing is an important step to prepare the data to form a machine learning model can understand. 

image

# AIM
The goal of this project is brief understanding of Text Preprocessing in Natural language processing.

## :page_facing_up: **INTRODUCTION**
Text preprocessing is a method to clean the text data and make it ready to feed data to the model. Text data contains noise in various forms like emotions, punctuation, text in a different case.

Whenever we have textual data, we need to apply several pre-processing steps to the data to transform words into numerical features that work with machine learning algorithms.

## What have I done?

1. Importing all the required libraries.

2. Brief explanation of Text preprocessing  steps.

* 1] Noise Removal

 * 2] Tokenization

* 3] Text Normalization

 * 4] Stemming

 * 5] Lemmatization

 * 6] Stopword Removal

 * 7] Part-of-Speech Tagging 

3. Pratical Implementation of word embedding techniques.

4. Upload  the Jupyter Notebook file.


## :page_facing_up: **BRIEF EXPLANATION**

In this I have cover various Text preprocessing steps.

# :pushpin: Noise Removal

In natural language processing, noise removal is a text preprocessing task devoted to stripping text of formatting. Noise removal is about removing characters digits and pieces of text that can interfere with your text analysis. Noise removal is one of the most essential text preprocessing steps.

# :pushpin: Tokenization

 Tokenization is the process of turning sensitive data into nonsensitive data called "tokens" that can be used in a database or internal system without bringing it into scope. Tokenization can be used to secure sensitive data by replacing the original data with an unrelated value of the same length and format.

# :pushpin: Text Normalization

Normalization is the process of converting a token into its base form.In the normalization process, the inflectional form of a word is removed so that the base form can be obtained.

# :pushpin: Stemming
Stemming is used in information retrieval systems like search engines. It is used to determine domain vocabularies in domain analysis.
# :pushpin:  Lemmatization

Lemmatization is the process of grouping together the different inflected forms of a word so they can be analyzed as a single item.
# :pushpin: Stopword Removal
 The words which are generally filtered out before processing a natural language are called stop words. These are actually the most common words in any language (like articles, prepositions, pronouns, conjunctions, etc) and does not add much information to the text.
# :pushpin: Part-of-Speech Tagging

Part-of-speech (POS) tagging is a popular Natural Language Processing process which refers to categorizing words in a text (corpus) in correspondence with a particular part of speech, depending on the definition of the word and its context.


## :key: LIBRARIES USED

* nltk
* re
* word_tokenize
* stopwords 
* PorterStemmer
* WordNetLemmatizer

# :thought_balloon: REFERENCES
https://basilkjose.medium.com/data-preprocessing-natural-language-competition-processing-dcbbf9d014e8

https://www.analyticsvidhya.com/blog/2021/06/text-preprocessing-in-nlp-with-python-codes/


# :bulb: CONCLUSION

In this, I have discussed the basic preprocessing steps that are required before building models in natural language processing that are fundamentals. These include tokenization, lowercasing the text, stop word removal, stemming, and lemmatization. Although the range with which natural language processing could be implemented is wide, much research has been going on in this particular topic.


## Author
Code Contributed by Tanvi Deshmukh.
![MIT License](https://img.shields.io/badge/Made_With_Jupyter-2CA5E0?style=for-the-badge_Color=whit)